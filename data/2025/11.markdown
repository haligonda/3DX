[![Hugging Face's logo](https://huggingface.co/front/assets/huggingface_logo-noborder.svg) Hugging Face](https://huggingface.co/)
  * [](https://huggingface.co/models)
  * [](https://huggingface.co/datasets)
  * [](https://huggingface.co/spaces)
  * [](https://huggingface.co/docs)
  * [](https://huggingface.co/enterprise)
  * [Pricing](https://huggingface.co/pricing)
  * * * *
  * [Log In](https://huggingface.co/login)
  * [Sign Up](https://huggingface.co/join)


new
Get trending papers in your email inbox once a day!
Get trending papers in your email inbox!
[Subscribe](https://huggingface.co/login?next=%2Fpapers)
# Daily Papers
## by[![](https://huggingface.co/front/assets/papers-by.png)AK](https://huggingface.co/akhaliq) and the research community 
  * Daily 
  * Weekly 
  * Monthly 

[](https://huggingface.co/papers/trending)
[](https://huggingface.co/papers/month/2025-10)
November
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.04570.png)](https://huggingface.co/papers/2511.04570)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/e8KDV6J29tviXlIpLZPq6.png) lkdhy
[ 160 ](https://huggingface.co/login?next=%2Fpapers%2F2511.04570)
### [Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm](https://huggingface.co/papers/2511.04570)
[![OpenMOSS-Team](https://cdn-uploads.huggingface.co/production/uploads/61457b8deff2c9fdb4de4988/N5b9663zQ4uq5_OTNlnmw.png) OpenMOSS](https://huggingface.co/OpenMOSS-Team)
[120](https://huggingface.co/papers/2511.04570) [](https://huggingface.co/papers/2511.04570#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.03276.png)](https://huggingface.co/papers/2511.03276)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/62a7362fd1e7a011fd4e31a7/ZY_mwH-sI0o05SHpLqwc7.png) jinjieni
[ 95 ](https://huggingface.co/login?next=%2Fpapers%2F2511.03276)
### [Diffusion Language Models are Super Data Learners](https://huggingface.co/papers/2511.03276)
[![NationalUniversityofSingapore](https://cdn-uploads.huggingface.co/production/uploads/630ca0817dacb93b33506ce7/ZYUmpSMsa5Whihw3me2Bw.png) National University of Singapore](https://huggingface.co/NationalUniversityofSingapore)
[149](https://huggingface.co/papers/2511.03276) [](https://huggingface.co/papers/2511.03276#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02778.png)](https://huggingface.co/papers/2511.02778)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/64440be5af034cdfd69ca3a7/qmx24QiDFT29vleCxL9TX.jpeg) KevinQHLin
[ 95 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02778)
### [VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual Representation](https://huggingface.co/papers/2511.02778)
[![CSU-JPG](https://cdn-uploads.huggingface.co/production/uploads/62333a88fd7bb4a39b92d387/MHfLrhVz0KqH6ydx1UrOc.jpeg) Jinpeng Group](https://huggingface.co/CSU-JPG)
[87](https://huggingface.co/papers/2511.02778) [](https://huggingface.co/papers/2511.02778#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.25616.png)](https://huggingface.co/papers/2510.25616)
Submitted by ![](https://huggingface.co/avatars/915875e7c4118098ab460831d5e8ef0e.svg) tttonyalpha
[ 88 ](https://huggingface.co/login?next=%2Fpapers%2F2510.25616)
### [Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization](https://huggingface.co/papers/2510.25616)
[
  * ![](https://huggingface.co/avatars/85d5797197bc89775922fccd6c4db3ce.svg)
  * ![](https://huggingface.co/avatars/915875e7c4118098ab460831d5e8ef0e.svg)
  * · 5 authors 

](https://huggingface.co/papers/2510.25616)
[22](https://huggingface.co/papers/2510.25616) [](https://huggingface.co/papers/2510.25616#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.22115.png)](https://huggingface.co/papers/2510.22115)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/677e8c5624bd3d7373584b0c/36DAI9UR_q3F4LqKZEjho.jpeg) zzqsmall
[ 80 ](https://huggingface.co/login?next=%2Fpapers%2F2510.22115)
### [Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation](https://huggingface.co/papers/2510.22115)
[![inclusionAI](https://cdn-uploads.huggingface.co/production/uploads/662e1f9da266499277937d33/fyKuazRifqiaIO34xrhhm.jpeg) inclusionAI](https://huggingface.co/inclusionAI)
[](https://huggingface.co/papers/2510.22115#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.04460.png)](https://huggingface.co/papers/2511.04460)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 79 ](https://huggingface.co/login?next=%2Fpapers%2F2511.04460)
### [V-Thinker: Interactive Thinking with Images](https://huggingface.co/papers/2511.04460)
[
  * · 13 authors 

](https://huggingface.co/papers/2511.04460)
[67](https://huggingface.co/papers/2511.04460) [](https://huggingface.co/papers/2511.04460#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.27492.png)](https://huggingface.co/papers/2510.27492)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 78 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27492)
### [ThinkMorph: Emergent Properties in Multimodal Interleaved Chain-of-Thought Reasoning](https://huggingface.co/papers/2510.27492)
[
  * ![](https://huggingface.co/avatars/f92240519132c693de30c133ca784322.svg)
  * ![](https://huggingface.co/avatars/a95f9527722845a5414d86180c8e945d.svg)
  * ![](https://huggingface.co/avatars/e12efb8e030688a0afcc72176b453fb3.svg)
  * · 8 authors 

](https://huggingface.co/papers/2510.27492)
[89](https://huggingface.co/papers/2510.27492) [](https://huggingface.co/papers/2510.27492#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.24411.png)](https://huggingface.co/papers/2510.24411)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/1617207525789-noauth.png) QiushiSun
[ 70 ](https://huggingface.co/login?next=%2Fpapers%2F2510.24411)
### [OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows](https://huggingface.co/papers/2510.24411)
[![hkunlp](https://cdn-uploads.huggingface.co/production/uploads/1639647572687-618767e4238063b4615d042b.jpeg) NLP Group of The University of Hong Kong](https://huggingface.co/hkunlp)
[35](https://huggingface.co/papers/2510.24411) [](https://huggingface.co/papers/2510.24411#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.03773.png)](https://huggingface.co/papers/2511.03773)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 63 ](https://huggingface.co/login?next=%2Fpapers%2F2511.03773)
### [Scaling Agent Learning via Experience Synthesis](https://huggingface.co/papers/2511.03773)
[![metaresearch](https://cdn-uploads.huggingface.co/production/uploads/66b25f3f58babfaeb76112dc/2GmiaF075AZ7BcE538oPk.png) Meta Research](https://huggingface.co/metaresearch)
[](https://huggingface.co/papers/2511.03773#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.25602.png)](https://huggingface.co/papers/2510.25602)
Submitted by ![](https://huggingface.co/avatars/5c8dc0df57596c526b2bccea21835f53.svg) ChenMnZ
[ 63 ](https://huggingface.co/login?next=%2Fpapers%2F2510.25602)
### [INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats](https://huggingface.co/papers/2510.25602)
[![ByteDance-Seed](https://cdn-uploads.huggingface.co/production/uploads/6535c9e88bde2fae19b6fb25/flkDUqd_YEuFsjeNET3r-.png) ByteDance Seed](https://huggingface.co/ByteDance-Seed)
[38](https://huggingface.co/papers/2510.25602) [](https://huggingface.co/papers/2510.25602#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.27688.png)](https://huggingface.co/papers/2510.27688)
Submitted by ![](https://huggingface.co/avatars/9c13810fe789ddcd9cefd4f2c924e4aa.svg) cccczshao
[ 59 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27688)
### [Continuous Autoregressive Language Models](https://huggingface.co/papers/2510.27688)
[![tencent](https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/Lp3m-XLpjQGwBItlvn69q.png) Tencent](https://huggingface.co/tencent)
[418](https://huggingface.co/papers/2510.27688) [](https://huggingface.co/papers/2510.27688#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.25889.png)](https://huggingface.co/papers/2510.25889)
Submitted by ![](https://huggingface.co/avatars/3bcacd9b778a146e88e20887b0b00720.svg) zoeyuchao
[ 58 ](https://huggingface.co/login?next=%2Fpapers%2F2510.25889)
### [π_RL: Online RL Fine-tuning for Flow-based Vision-Language-Action Models](https://huggingface.co/papers/2510.25889)
[![RLinf](https://cdn-uploads.huggingface.co/production/uploads/689ea8a1a73ecc6940dbba3d/T2RGCw18z6lYP1WfkIGJ3.jpeg) RLinf](https://huggingface.co/RLinf)
[](https://huggingface.co/papers/2510.25889#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02779.png)](https://huggingface.co/papers/2511.02779)
Submitted by ![](https://huggingface.co/avatars/f3c5560d500c699e452986a6a45ba3ee.svg) YiyangAiLab
[ 52 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02779)
### [When Visualizing is the First Step to Reasoning: MIRA, a Benchmark for Visual Chain-of-Thought](https://huggingface.co/papers/2511.02779)
[![ByteDance-Seed](https://cdn-uploads.huggingface.co/production/uploads/6535c9e88bde2fae19b6fb25/flkDUqd_YEuFsjeNET3r-.png) ByteDance Seed](https://huggingface.co/ByteDance-Seed)
[](https://huggingface.co/papers/2511.02779#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.03334.png)](https://huggingface.co/papers/2511.03334)
Submitted by ![](https://huggingface.co/avatars/0ff3127b513552432a7c651e21d7f283.svg) wangsssssss
[ 47 ](https://huggingface.co/login?next=%2Fpapers%2F2511.03334)
### [UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions](https://huggingface.co/papers/2511.03334)
[![NJU](https://cdn-uploads.huggingface.co/production/uploads/1662276136108-6314518e5f47a1896274d080.jpeg) Nanjing University](https://huggingface.co/NJU)
[](https://huggingface.co/papers/2511.03334#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.27545.png)](https://huggingface.co/papers/2510.27545)
Submitted by ![](https://huggingface.co/avatars/d186d0859046b35723fe1156d8f68917.svg) alexiglad
[ 47 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27545)
### [EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities](https://huggingface.co/papers/2510.27545)
[
  * ![](https://huggingface.co/avatars/4be19af5efc0b676523ae79959cceb33.svg)
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/fhkTu3jWHuPkZvNH4uvOV.png)
  * · 8 authors 

](https://huggingface.co/papers/2510.27545)
[](https://huggingface.co/papers/2510.27545#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.03001.png)](https://huggingface.co/papers/2511.03001)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 45 ](https://huggingface.co/login?next=%2Fpapers%2F2511.03001)
### [LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation](https://huggingface.co/papers/2511.03001)
[
  * ![](https://huggingface.co/avatars/5dc3225be1194467b30691b5d33c7b19.svg)
  * · 6 authors 

](https://huggingface.co/papers/2511.03001)
[](https://huggingface.co/papers/2511.03001#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.00086.png)](https://huggingface.co/papers/2511.00086)
Submitted by ![](https://huggingface.co/avatars/c2f6507fa7dcf00fe0151462533f1c2c.svg) FairyFali
[ 40 ](https://huggingface.co/login?next=%2Fpapers%2F2511.00086)
### [Generalizing Test-time Compute-optimal Scaling as an Optimizable Graph](https://huggingface.co/papers/2511.00086)
[ Pennsylvania State University](https://huggingface.co/PennState)
[](https://huggingface.co/papers/2511.00086#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.00062.png)](https://huggingface.co/papers/2511.00062)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 37 ](https://huggingface.co/login?next=%2Fpapers%2F2511.00062)
### [World Simulation with Video Foundation Models for Physical AI](https://huggingface.co/papers/2511.00062)
[
  * ![](https://huggingface.co/avatars/aff6df6a6b9d9e415b7f1931dd270a38.svg)
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/649f05367b57fab3a5b27c8b/UDJB4yqF2NmaRwCyTOfcl.jpeg)
  * · 89 authors 

](https://huggingface.co/papers/2511.00062)
[](https://huggingface.co/papers/2511.00062#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01295.png)](https://huggingface.co/papers/2511.01295)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/KXQaAxulqr8jNBSpEaYM4.png) CodeGoat24
[ 36 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01295)
### [UniREditBench: A Unified Reasoning-based Image Editing Benchmark](https://huggingface.co/papers/2511.01295)
[![Fudan-University](https://cdn-uploads.huggingface.co/production/uploads/6437eca0819f3ab20d162e14/kWv0cGlAhAG3iNWVxowkJ.png) Fudan University](https://huggingface.co/Fudan-University)
[37](https://huggingface.co/papers/2511.01295) [](https://huggingface.co/papers/2511.01295#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01678.png)](https://huggingface.co/papers/2511.01678)
Submitted by ![](https://huggingface.co/avatars/15c325d8c2273ff63569f23015e98486.svg) JacobYuan
[ 33 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01678)
### [UniLumos: Fast and Unified Image and Video Relighting with Physics-Plausible Feedback](https://huggingface.co/papers/2511.01678)
[![Alibaba-DAMO-Academy](https://cdn-uploads.huggingface.co/production/uploads/6808e64de5dd22427c006e10/9J3vdB62CdeTOd_YrGh9w.jpeg) DAMO Academy](https://huggingface.co/Alibaba-DAMO-Academy)
[48](https://huggingface.co/papers/2511.01678) [](https://huggingface.co/papers/2511.01678#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.24788.png)](https://huggingface.co/papers/2510.24788)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/xp34hfiSLf-DiE1DVVhHk.png) Xinjiansz
[ 33 ](https://huggingface.co/login?next=%2Fpapers%2F2510.24788)
### [The Underappreciated Power of Vision Models for Graph Structural Understanding](https://huggingface.co/papers/2510.24788)
[
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/Mja7cpws4gb2Jmdj_foPA.png)
  * ![](https://huggingface.co/avatars/dab8b90db8bbd00806268fe276e3ea36.svg)
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/xp34hfiSLf-DiE1DVVhHk.png)
  * · 9 authors 

](https://huggingface.co/papers/2510.24788)
[](https://huggingface.co/papers/2510.24788#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01163.png)](https://huggingface.co/papers/2511.01163)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/JFH3ZTPvlaVSg4RJJBb6L.jpeg) cheryyunl
[ 30 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01163)
### [ROVER: Benchmarking Reciprocal Cross-Modal Reasoning for Omnimodal Generation](https://huggingface.co/papers/2511.01163)
[
  * ![](https://huggingface.co/avatars/2cda4182dfd11a1e94743639e62328ea.svg)
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/630cfc45b66f088d547b2768/9-dMts2xFVbPmPHJGGqBx.png)
  * · 10 authors 

](https://huggingface.co/papers/2511.01163)
[](https://huggingface.co/papers/2511.01163#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.24794.png)](https://huggingface.co/papers/2510.24794)
Submitted by ![](https://huggingface.co/avatars/aa821e632ce314cb636c3a1469d61017.svg) PeterKKQ
[ 30 ](https://huggingface.co/login?next=%2Fpapers%2F2510.24794)
### [MR-Align: Meta-Reasoning Informed Factuality Alignment for Large Reasoning Models](https://huggingface.co/papers/2510.24794)
[
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6729bbdebd5ca35b8ed8cc1c/FaklBmA2UqJrxuF2balW0.jpeg)
  * ![](https://huggingface.co/avatars/b17b0293bc47ffc65585732e32db66f8.svg)
  * ![](https://huggingface.co/avatars/aa821e632ce314cb636c3a1469d61017.svg)
  * · 12 authors 

](https://huggingface.co/papers/2510.24794)
[](https://huggingface.co/papers/2510.24794#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.27606.png)](https://huggingface.co/papers/2510.27606)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/63859cf3b2906edaf83af9f0/kajwuVzd4pDucSPlwghxo.png) yuhangzang
[ 27 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27606)
### [Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning](https://huggingface.co/papers/2510.27606)
[![internlm](https://cdn-uploads.huggingface.co/production/uploads/6445306bc525660aa2099ecc/ipmEgm86UIby2q5q7NkKm.jpeg) Intern Large Models](https://huggingface.co/internlm)
[56](https://huggingface.co/papers/2510.27606) [](https://huggingface.co/papers/2510.27606#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.26788.png)](https://huggingface.co/papers/2510.26788)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/1669881620925-noauth.jpeg) QPHutu
[ 27 ](https://huggingface.co/login?next=%2Fpapers%2F2510.26788)
### [Defeating the Training-Inference Mismatch via FP16](https://huggingface.co/papers/2510.26788)
[![sail](https://cdn-uploads.huggingface.co/production/uploads/1643440185801-5df833bdda6d0311fd3d5403.png) Sea AI Lab](https://huggingface.co/sail)
[131](https://huggingface.co/papers/2510.26788) [](https://huggingface.co/papers/2510.26788#community)
[](https://huggingface.co/papers/2510.26236)
Submitted by ![](https://huggingface.co/avatars/29fbe7a537a71160b2c301efe7c830d1.svg) Kyungminn
[ 27 ](https://huggingface.co/login?next=%2Fpapers%2F2510.26236)
### [PHUMA: Physically-Grounded Humanoid Locomotion Dataset](https://huggingface.co/papers/2510.26236)
[![DAVIAN-Robotics](https://cdn-uploads.huggingface.co/production/uploads/630461624ec2dfa82a5ad7e7/0NA6xGIRlNalvgIxvZIXD.png) DAVIAN Robotics](https://huggingface.co/DAVIAN-Robotics)
[108](https://huggingface.co/papers/2510.26236) [](https://huggingface.co/papers/2510.26236#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.04670.png)](https://huggingface.co/papers/2511.04670)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 25 ](https://huggingface.co/login?next=%2Fpapers%2F2511.04670)
### [Cambrian-S: Towards Spatial Supersensing in Video](https://huggingface.co/papers/2511.04670)
[
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/1652346592327-noauth.jpeg)
  * · 15 authors 

](https://huggingface.co/papers/2511.04670)
[](https://huggingface.co/papers/2511.04670#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.03601.png)](https://huggingface.co/papers/2511.03601)
Submitted by ![](https://huggingface.co/avatars/6280b33a6b1532ee938afd4aa303f709.svg) giantPanda0906
[ 25 ](https://huggingface.co/login?next=%2Fpapers%2F2511.03601)
### [Step-Audio-EditX Technical Report](https://huggingface.co/papers/2511.03601)
[![stepfun-ai](https://cdn-uploads.huggingface.co/production/uploads/66935cee39002fc0569c2943/Qv8QPbkgoKE3wR4jTzHiy.png) StepFun](https://huggingface.co/stepfun-ai)
[](https://huggingface.co/papers/2511.03601#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02243.png)](https://huggingface.co/papers/2511.02243)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/673c7319d11b1c2e246ead9c/IjFIO--N7Hm_BOEafhEQv.jpeg) DogNeverSleep
[ 23 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02243)
### [When Modalities Conflict: How Unimodal Reasoning Uncertainty Governs Preference Dynamics in MLLMs](https://huggingface.co/papers/2511.02243)
[
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/673c7319d11b1c2e246ead9c/IjFIO--N7Hm_BOEafhEQv.jpeg)
  * · 7 authors 

](https://huggingface.co/papers/2511.02243)
[](https://huggingface.co/papers/2511.02243#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01266.png)](https://huggingface.co/papers/2511.01266)
Submitted by ![](https://huggingface.co/avatars/699baf06ec818650dec5752aca87c5b4.svg) alex4727
[ 23 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01266)
### [MotionStream: Real-Time Video Generation with Interactive Motion Controls](https://huggingface.co/papers/2511.01266)
[![adobe](https://cdn-uploads.huggingface.co/production/uploads/1645217431826-61e35e517ac6b6d06cfa8081.png) Adobe](https://huggingface.co/adobe)
[](https://huggingface.co/papers/2511.01266#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.27363.png)](https://huggingface.co/papers/2510.27363)
Submitted by ![](https://huggingface.co/avatars/b495ec5b35b15fea245ef490b83d1856.svg) MengjieDeng
[ 22 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27363)
### [ToolScope: An Agentic Framework for Vision-Guided and Long-Horizon Tool Use](https://huggingface.co/papers/2510.27363)
[
  * ![](https://huggingface.co/avatars/be97941e60064e5dd806c6fe9db3c537.svg)
  * ![](https://huggingface.co/avatars/b495ec5b35b15fea245ef490b83d1856.svg)
  * · 3 authors 

](https://huggingface.co/papers/2510.27363)
[18](https://huggingface.co/papers/2510.27363) [](https://huggingface.co/papers/2510.27363#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.27684.png)](https://huggingface.co/papers/2510.27684)
Submitted by ![](https://huggingface.co/avatars/f5747fdbe495d1296fed9d16d8c95857.svg) yl-1993
[ 21 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27684)
### [Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals](https://huggingface.co/papers/2510.27684)
[![sensenova](https://cdn-uploads.huggingface.co/production/uploads/6626a471430a124253f197c8/6zZrQVns6vGanbZ4oN4gX.png) SenseNova](https://huggingface.co/sensenova)
[214](https://huggingface.co/papers/2510.27684) [](https://huggingface.co/papers/2510.27684#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02687.png)](https://huggingface.co/papers/2511.02687)
Submitted by ![](https://huggingface.co/avatars/431bc46350cbbe996bb058e03ccc2fd0.svg) trdavidson
[ 20 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02687)
### [The Collaboration Gap](https://huggingface.co/papers/2511.02687)
[![MicrosoftResearch](https://cdn-uploads.huggingface.co/production/uploads/6529a4f2f1205983224fa513/PeuVr7jSuJflmDBBGxoDX.png) Microsoft Research](https://huggingface.co/MicrosoftResearch)
[](https://huggingface.co/papers/2511.02687#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.00602.png)](https://huggingface.co/papers/2511.00602)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/61001311e043e15c13412d30/6yAbTweYR16XtxMBEyOWl.png) pminervini
[ 20 ](https://huggingface.co/login?next=%2Fpapers%2F2511.00602)
### [OpenSIR: Open-Ended Self-Improving Reasoner](https://huggingface.co/papers/2511.00602)
[![EdinburghNLP](https://cdn-uploads.huggingface.co/production/uploads/5fbfd09ee366524fe8e97cd3/KBva4SboTuDXRdYqWZsCX.png) EdinburghNLP - Natural Language Processing Group at the University of Edinburgh](https://huggingface.co/EdinburghNLP)
[0](https://huggingface.co/papers/2511.00602) [](https://huggingface.co/papers/2511.00602#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.00279.png)](https://huggingface.co/papers/2511.00279)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 20 ](https://huggingface.co/login?next=%2Fpapers%2F2511.00279)
### [LongCat-Flash-Omni Technical Report](https://huggingface.co/papers/2511.00279)
[
  * ![](https://huggingface.co/avatars/ef52044fc03b3178c5a868f3c979345c.svg)
  * · 132 authors 

](https://huggingface.co/papers/2511.00279)
[](https://huggingface.co/papers/2511.00279#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02734.png)](https://huggingface.co/papers/2511.02734)
Submitted by ![](https://huggingface.co/avatars/eb9a0441986be50274c5e661f7039e2c.svg) JiayuJeff
[ 19 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02734)
### [CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents](https://huggingface.co/papers/2511.02734)
[
  * ![](https://huggingface.co/avatars/eb9a0441986be50274c5e661f7039e2c.svg)
  * · 7 authors 

](https://huggingface.co/papers/2511.02734)
[](https://huggingface.co/papers/2511.02734#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.27266.png)](https://huggingface.co/papers/2510.27266)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 19 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27266)
### [HyperClick: Advancing Reliable GUI Grounding via Uncertainty Calibration](https://huggingface.co/papers/2510.27266)
[
  * · 11 authors 

](https://huggingface.co/papers/2510.27266)
[](https://huggingface.co/papers/2510.27266#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.23095.png)](https://huggingface.co/papers/2510.23095)
Submitted by ![](https://huggingface.co/avatars/cd101a2c5188b48a1874f20756eb8f51.svg) GingL
[ 18 ](https://huggingface.co/login?next=%2Fpapers%2F2510.23095)
### [Revisiting Multimodal Positional Encoding in Vision-Language Models](https://huggingface.co/papers/2510.23095)
[![Qwen](https://cdn-uploads.huggingface.co/production/uploads/620760a26e3b7210c2ff1943/-s1gyJfvbE1RgO5iBeNOi.png) Qwen](https://huggingface.co/Qwen)
[](https://huggingface.co/papers/2510.23095#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.03929.png)](https://huggingface.co/papers/2511.03929)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 16 ](https://huggingface.co/login?next=%2Fpapers%2F2511.03929)
### [NVIDIA Nemotron Nano V2 VL](https://huggingface.co/papers/2511.03929)
[![nvidia](https://cdn-uploads.huggingface.co/production/uploads/1613114437487-60262a8e0703121c822a80b6.png) NVIDIA](https://huggingface.co/nvidia)
[](https://huggingface.co/papers/2511.03929#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.27571.png)](https://huggingface.co/papers/2510.27571)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/QxGBsnk1cNsBEPqSx4ae-.jpeg) songtingyu
[ 16 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27571)
### [Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum](https://huggingface.co/papers/2510.27571)
[![Alibaba-NLP](https://cdn-uploads.huggingface.co/production/uploads/63fc4c00a3c067e62899d32b/dfd_EcIfylvu3sdc2WMqX.png) Alibaba-NLP](https://huggingface.co/Alibaba-NLP)
[](https://huggingface.co/papers/2510.27571#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01833.png)](https://huggingface.co/papers/2511.01833)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 15 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01833)
### [TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning](https://huggingface.co/papers/2511.01833)
[
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/67ff7f687351095d4b606b84/KhNPmbBC3zghuP5h1MK-c.png)
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/62c66504031996c36c86976a/wIq0YJhkWnEhlzsh-TGYO.png)
  * · 9 authors 

](https://huggingface.co/papers/2511.01833)
[17](https://huggingface.co/papers/2511.01833) [](https://huggingface.co/papers/2511.01833#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.24940.png)](https://huggingface.co/papers/2510.24940)
Submitted by ![](https://huggingface.co/avatars/e10e2f8516d1451fd85e17b5a0ba978d.svg) yaochenzhu
[ 15 ](https://huggingface.co/login?next=%2Fpapers%2F2510.24940)
### [SemCoT: Accelerating Chain-of-Thought Reasoning through Semantically-Aligned Implicit Tokens](https://huggingface.co/papers/2510.24940)
[![LinkedIn](https://cdn-uploads.huggingface.co/production/uploads/6697e834fd52271e0b9ce8d8/VSBDJkmYgk4-LeXgTKThN.png) LinkedIn](https://huggingface.co/LinkedIn)
[13](https://huggingface.co/papers/2510.24940) [](https://huggingface.co/papers/2510.24940#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02818.png)](https://huggingface.co/papers/2511.02818)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/66fce04d927ec45504514afd/lA_bTErY7JywT6xbzdflo.jpeg) pratinavsetharya
[ 13 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02818)
### [Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning](https://huggingface.co/papers/2511.02818)
[![Lexsi](https://cdn-uploads.huggingface.co/production/uploads/63cbbcb9f488db9bb3beeaa1/b0eHmC8iYVQCyqqaLFfA6.png) Lexsi Labs](https://huggingface.co/Lexsi)
[](https://huggingface.co/papers/2511.02818#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.26909.png)](https://huggingface.co/papers/2510.26909)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/RBybzGRphbiV2MXYHrDoc.png) mbreuss
[ 13 ](https://huggingface.co/login?next=%2Fpapers%2F2510.26909)
### [NaviTrace: Evaluating Embodied Navigation of Vision-Language Models](https://huggingface.co/papers/2510.26909)
[![leggedrobotics](https://cdn-uploads.huggingface.co/production/uploads/66b85828324dd1598bad739f/NxcyiB-gpFlU5sLTnepe2.png) Robotic Systems Lab - ETH Zürich](https://huggingface.co/leggedrobotics)
[9](https://huggingface.co/papers/2510.26909) [](https://huggingface.co/papers/2510.26909#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.04307.png)](https://huggingface.co/papers/2511.04307)
Submitted by ![](https://huggingface.co/avatars/b3c4035c48169c1bfb04a439fce3499f.svg) vyokky
[ 12 ](https://huggingface.co/login?next=%2Fpapers%2F2511.04307)
### [GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents](https://huggingface.co/papers/2511.04307)
[![microsoft](https://cdn-uploads.huggingface.co/production/uploads/1583646260758-5e64858c87403103f9f1055d.png) Microsoft](https://huggingface.co/microsoft)
[](https://huggingface.co/papers/2511.04307#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.03774.png)](https://huggingface.co/papers/2511.03774)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/63b7b2c6bd2d153522821766/aHtga-_OUdOrg_TRrXO08.jpeg) mucai
[ 12 ](https://huggingface.co/login?next=%2Fpapers%2F2511.03774)
### [Contamination Detection for VLMs using Multi-Modal Semantic Perturbation](https://huggingface.co/papers/2511.03774)
[![uw-madison](https://cdn-uploads.huggingface.co/production/uploads/68e396f2b5bb631e9b2fac9a/IYmUaLUc_rDVNC6F7-k8M.png) University of Wisconsin - Madison](https://huggingface.co/uw-madison)
[](https://huggingface.co/papers/2511.03774#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02802.png)](https://huggingface.co/papers/2511.02802)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/66fce04d927ec45504514afd/lA_bTErY7JywT6xbzdflo.jpeg) pratinavsetharya
[ 12 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02802)
### [TabTune: A Unified Library for Inference and Fine-Tuning Tabular Foundation Models](https://huggingface.co/papers/2511.02802)
[![Lexsi](https://cdn-uploads.huggingface.co/production/uploads/63cbbcb9f488db9bb3beeaa1/b0eHmC8iYVQCyqqaLFfA6.png) Lexsi Labs](https://huggingface.co/Lexsi)
[](https://huggingface.co/papers/2511.02802#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01340.png)](https://huggingface.co/papers/2511.01340)
Submitted by ![](https://huggingface.co/avatars/c2f17a4a636973817fd5da2ae6dbaac3.svg) abhi1nandy2
[ 12 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01340)
### [left|,circlearrowright,text{BUS},right|: A Large and Diverse Multimodal Benchmark for evaluating the ability of Vision-Language Models to understand Rebus Puzzles](https://huggingface.co/papers/2511.01340)
[
  * · 4 authors 

](https://huggingface.co/papers/2511.01340)
[](https://huggingface.co/papers/2511.01340#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01294.png)](https://huggingface.co/papers/2511.01294)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/1679399015950-636d12455aaed143cd665607.png) ZarkLngeW
[ 12 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01294)
### [Kinematify: Open-Vocabulary Synthesis of High-DoF Articulated Objects](https://huggingface.co/papers/2511.01294)
[![DEEMOSTECH](https://cdn-uploads.huggingface.co/production/uploads/642704738a61aabae65be84d/VU59bPTS9RR4pFC7LEQmo.png) DEEMOS Technology](https://huggingface.co/DEEMOSTECH)
[](https://huggingface.co/papers/2511.01294#community)
[](https://huggingface.co/papers/2510.27623)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 12 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27623)
### [Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning](https://huggingface.co/papers/2510.27623)
[
  * ![](https://huggingface.co/avatars/11c8edb0967491822277a8a0d3ff3d31.svg)
  * ![](https://huggingface.co/avatars/9bb8205b889337df5d321539c9b5d69d.svg)
  * ![](https://huggingface.co/avatars/cfef589b87bd424e333b2a25063528f8.svg)
  * · 10 authors 

](https://huggingface.co/papers/2510.27623)
[](https://huggingface.co/papers/2510.27623#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.26707.png)](https://huggingface.co/papers/2510.26707)
Submitted by ![](https://huggingface.co/avatars/9d708d88574cea2f17af37b659ef6a53.svg) MeharBhatia
[ 12 ](https://huggingface.co/login?next=%2Fpapers%2F2510.26707)
### [Value Drifts: Tracing Value Alignment During LLM Post-Training](https://huggingface.co/papers/2510.26707)
[![McGill-NLP](https://cdn-uploads.huggingface.co/production/uploads/1651301909677-5fa9ff3ea13e063b8b2b60cb.png) McGill NLP Group](https://huggingface.co/McGill-NLP)
[](https://huggingface.co/papers/2510.26707#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.04217.png)](https://huggingface.co/papers/2511.04217)
Submitted by ![](https://huggingface.co/avatars/47afd9ed11fafd2c70f6fa8c570d1038.svg) h-otsuka
[ 11 ](https://huggingface.co/login?next=%2Fpapers%2F2511.04217)
### [The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms](https://huggingface.co/papers/2511.04217)
[
  * ![](https://huggingface.co/avatars/47afd9ed11fafd2c70f6fa8c570d1038.svg)
  * · 6 authors 

](https://huggingface.co/papers/2511.04217)
[](https://huggingface.co/papers/2511.04217#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.26865.png)](https://huggingface.co/papers/2510.26865)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/65b21047f5d76208991e463e/6ML4lLz-vUr1HdWR3Jo-L.jpeg) philokey
[ 11 ](https://huggingface.co/login?next=%2Fpapers%2F2510.26865)
### [Do Vision-Language Models Measure Up? Benchmarking Visual Measurement Reading with MeasureBench](https://huggingface.co/papers/2510.26865)
[![BAAI](https://cdn-uploads.huggingface.co/production/uploads/1664511063789-632c234f42c386ebd2710434.png) Beijing Academy of Artificial Intelligence](https://huggingface.co/BAAI)
[5](https://huggingface.co/papers/2510.26865) [](https://huggingface.co/papers/2510.26865#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01857.png)](https://huggingface.co/papers/2511.01857)
Submitted by ![](https://huggingface.co/avatars/f0512561780625d9be43f00dfd5cd46d.svg) zuom
[ 10 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01857)
### [Trove: A Flexible Toolkit for Dense Retrieval](https://huggingface.co/papers/2511.01857)
[![BatsResearch](https://cdn-uploads.huggingface.co/production/uploads/608849cadf398c3b285ce95b/oFrkKbxGUKIW2W8FFGUje.png) Bats Research](https://huggingface.co/BatsResearch)
[39](https://huggingface.co/papers/2511.01857) [](https://huggingface.co/papers/2511.01857#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.27258.png)](https://huggingface.co/papers/2510.27258)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/647bf082aba7062fe5c51ca9/p4lY9IjHiWZETKmFq1mtU.jpeg) yifAI
[ 10 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27258)
### [Higher-order Linear Attention](https://huggingface.co/papers/2510.27258)
[![math-ai](https://cdn-uploads.huggingface.co/production/uploads/647bf082aba7062fe5c51ca9/xRvQyLKDwSslb31WlKO6-.png) math-ai](https://huggingface.co/math-ai)
[36](https://huggingface.co/papers/2510.27258) [](https://huggingface.co/papers/2510.27258#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.03628.png)](https://huggingface.co/papers/2511.03628)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 9 ](https://huggingface.co/login?next=%2Fpapers%2F2511.03628)
### [LiveTradeBench: Seeking Real-World Alpha with Large Language Models](https://huggingface.co/papers/2511.03628)
[
  * · 3 authors 

](https://huggingface.co/papers/2511.03628)
[46](https://huggingface.co/papers/2511.03628) [](https://huggingface.co/papers/2511.03628#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01618.png)](https://huggingface.co/papers/2511.01618)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/67dc162ec8c00778e8689f42/_y_tO6W3ONOkOWbumAFXA.png) Osilly
[ 9 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01618)
### [Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models](https://huggingface.co/papers/2511.01618)
[
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/67dc162ec8c00778e8689f42/_y_tO6W3ONOkOWbumAFXA.png)
  * · 14 authors 

](https://huggingface.co/papers/2511.01618)
[](https://huggingface.co/papers/2511.01618#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01937.png)](https://huggingface.co/papers/2511.01937)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6380e53efb49cd1c12052c17/b5CweexfrVn-W_xto2agR.jpeg) BounharAbdelaziz
[ 9 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01937)
### [Shorter but not Worse: Frugal Reasoning via Easy Samples as Length Regularizers in Math RLVR](https://huggingface.co/papers/2511.01937)
[![MBZUAI-Paris](https://cdn-uploads.huggingface.co/production/uploads/6087e598e2b7cc3a117b0dc5/JUiDkClou70ZdFQaiZ3hK.png) MBZUAI-IFM Paris Lab](https://huggingface.co/MBZUAI-Paris)
[7](https://huggingface.co/papers/2511.01937) [](https://huggingface.co/papers/2511.01937#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.25976.png)](https://huggingface.co/papers/2510.25976)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/QgryioCNwCGDx_tdlHeym.png) Amitz244
[ 9 ](https://huggingface.co/login?next=%2Fpapers%2F2510.25976)
### [Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer](https://huggingface.co/papers/2510.25976)
[![weizmannscience](https://cdn-uploads.huggingface.co/production/uploads/1659014711791-624bebf604abc7ebb01789af.jpeg) Weizmann Institute of Science](https://huggingface.co/weizmannscience)
[](https://huggingface.co/papers/2510.25976#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02832.png)](https://huggingface.co/papers/2511.02832)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 8 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02832)
### [TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System](https://huggingface.co/papers/2511.02832)
[
  * ![](https://huggingface.co/avatars/ca2cc9b87f5ca5cd51606b2f9edf89d0.svg)
  * · 9 authors 

](https://huggingface.co/papers/2511.02832)
[](https://huggingface.co/papers/2511.02832#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02650.png)](https://huggingface.co/papers/2511.02650)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/4X8waDwiphbfKZySrYlFy.jpeg) kailinjiang
[ 8 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02650)
### [Can Visual Input Be Compressed? A Visual Token Compression Benchmark for Large Multimodal Models](https://huggingface.co/papers/2511.02650)
[
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/4X8waDwiphbfKZySrYlFy.jpeg)
  * · 12 authors 

](https://huggingface.co/papers/2511.02650)
[](https://huggingface.co/papers/2511.02650#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.27607.png)](https://huggingface.co/papers/2510.27607)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 8 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27607)
### [Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model](https://huggingface.co/papers/2510.27607)
[
  * ![](https://huggingface.co/avatars/b01d9aed87b077e4c650944b4180cb12.svg)
  * · 5 authors 

](https://huggingface.co/papers/2510.27607)
[](https://huggingface.co/papers/2510.27607#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.03146.png)](https://huggingface.co/papers/2511.03146)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 7 ](https://huggingface.co/login?next=%2Fpapers%2F2511.03146)
### [MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity](https://huggingface.co/papers/2511.03146)
[![ByteDance-Seed](https://cdn-uploads.huggingface.co/production/uploads/6535c9e88bde2fae19b6fb25/flkDUqd_YEuFsjeNET3r-.png) ByteDance Seed](https://huggingface.co/ByteDance-Seed)
[](https://huggingface.co/papers/2511.03146#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02347.png)](https://huggingface.co/papers/2511.02347)
Submitted by ![](https://huggingface.co/avatars/78347af4af42527d53e88d9969c5c934.svg) tristanli
[ 7 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02347)
### [LTD-Bench: Evaluating Large Language Models by Letting Them Draw](https://huggingface.co/papers/2511.02347)
[![tencent](https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/Lp3m-XLpjQGwBItlvn69q.png) Tencent](https://huggingface.co/tencent)
[](https://huggingface.co/papers/2511.02347#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01846.png)](https://huggingface.co/papers/2511.01846)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 7 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01846)
### [Towards Robust Mathematical Reasoning](https://huggingface.co/papers/2511.01846)
[
  * · 20 authors 

](https://huggingface.co/papers/2511.01846)
[34](https://huggingface.co/papers/2511.01846) [](https://huggingface.co/papers/2511.01846#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.26491.png)](https://huggingface.co/papers/2510.26491)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6421c749eaad1bcb28b11206/jvaBUG7Z5fv6lJMoH301q.jpeg) lez3f
[ 7 ](https://huggingface.co/login?next=%2Fpapers%2F2510.26491)
### [Data-Efficient RLVR via Off-Policy Influence Guidance](https://huggingface.co/papers/2510.26491)
[
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/sbEmJxiJg4-8rrXDqUuFy.jpeg)
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6421c749eaad1bcb28b11206/jvaBUG7Z5fv6lJMoH301q.jpeg)
  * · 11 authors 

](https://huggingface.co/papers/2510.26491)
[](https://huggingface.co/papers/2510.26491#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.04655.png)](https://huggingface.co/papers/2511.04655)
Submitted by ![](https://huggingface.co/avatars/795c63f2394080eec78ca7981d4a1f78.svg) jihanyang
[ 6 ](https://huggingface.co/login?next=%2Fpapers%2F2511.04655)
### [Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts](https://huggingface.co/papers/2511.04655)
[![nyu-visionx](https://cdn-uploads.huggingface.co/production/uploads/626dc5105f7327906f0b2a4e/Kn-QtZjE6TJE-syTndXIW.jpeg) NYU VisionX](https://huggingface.co/nyu-visionx)
[](https://huggingface.co/papers/2511.04655#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01775.png)](https://huggingface.co/papers/2511.01775)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 6 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01775)
### [How Far Are Surgeons from Surgical World Models? A Pilot Study on Zero-shot Surgical Video Generation with Expert Assessment](https://huggingface.co/papers/2511.01775)
[
  * ![](https://huggingface.co/avatars/0c18e409c23a3ac10c06da9a9530e18e.svg)
  * · 10 authors 

](https://huggingface.co/papers/2511.01775)
[](https://huggingface.co/papers/2511.01775#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01718.png)](https://huggingface.co/papers/2511.01718)
Submitted by ![](https://huggingface.co/avatars/52b9ee7f899ee5431ed37fd1db378d9e.svg) Wenxuan123
[ 6 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01718)
### [Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process](https://huggingface.co/papers/2511.01718)
[ HKUSTGZ](https://huggingface.co/HKUSTGZ)
[36](https://huggingface.co/papers/2511.01718) [](https://huggingface.co/papers/2511.01718#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.00839.png)](https://huggingface.co/papers/2511.00839)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/ZxdbXnPAFq_O20FAZuD4v.png) john-b-yang
[ 6 ](https://huggingface.co/login?next=%2Fpapers%2F2511.00839)
### [CodeClash: Benchmarking Goal-Oriented Software Engineering](https://huggingface.co/papers/2511.00839)
[![stanfordnlp](https://cdn-uploads.huggingface.co/production/uploads/1628624969199-6032802e1f993496bc14d9e3.png) Stanford NLP](https://huggingface.co/stanfordnlp)
[29](https://huggingface.co/papers/2511.00839) [](https://huggingface.co/papers/2511.00839#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.26887.png)](https://huggingface.co/papers/2510.26887)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 6 ](https://huggingface.co/login?next=%2Fpapers%2F2510.26887)
### [The Denario project: Deep knowledge AI agents for scientific discovery](https://huggingface.co/papers/2510.26887)
[
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6613dfa16fe9d892116b5f99/wY46oty2NuGniO3ioynuK.png)
  * · 36 authors 

](https://huggingface.co/papers/2510.26887)
[353](https://huggingface.co/papers/2510.26887) [](https://huggingface.co/papers/2510.26887#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.00405.png)](https://huggingface.co/papers/2511.00405)
Submitted by ![](https://huggingface.co/avatars/e7f9720ccd01bae32d0a03a1b0dacab5.svg) zhibinlan
[ 5 ](https://huggingface.co/login?next=%2Fpapers%2F2511.00405)
### [UME-R1: Exploring Reasoning-Driven Generative Multimodal Embeddings](https://huggingface.co/papers/2511.00405)
[
  * · 5 authors 

](https://huggingface.co/papers/2511.00405)
[4](https://huggingface.co/papers/2511.00405) [](https://huggingface.co/papers/2511.00405#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.24795.png)](https://huggingface.co/papers/2510.24795)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/623437bd4f78e3acb8bd14bd/6ZIRpE9We4TiMtzDBtPFS.jpeg) haonanzhang
[ 5 ](https://huggingface.co/login?next=%2Fpapers%2F2510.24795)
### [A Survey on Efficient Vision-Language-Action Models](https://huggingface.co/papers/2510.24795)
[ Tongji Unversity](https://huggingface.co/Tongji)
[65](https://huggingface.co/papers/2510.24795) [](https://huggingface.co/papers/2510.24795#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01914.png)](https://huggingface.co/papers/2511.01914)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 4 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01914)
### [iFlyBot-VLA Technical Report](https://huggingface.co/papers/2511.01914)
[
  * · 6 authors 

](https://huggingface.co/papers/2511.01914)
[](https://huggingface.co/papers/2511.01914#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.27044.png)](https://huggingface.co/papers/2510.27044)
Submitted by ![](https://huggingface.co/avatars/4d2fb7c1a5ad5dabdb8888fa2fe72e65.svg) Tanvirul
[ 4 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27044)
### [Limits of Generalization in RLVR: Two Case Studies in Mathematical Reasoning](https://huggingface.co/papers/2510.27044)
[
  * · 2 authors 

](https://huggingface.co/papers/2510.27044)
[0](https://huggingface.co/papers/2510.27044) [](https://huggingface.co/papers/2510.27044#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.17950.png)](https://huggingface.co/papers/2510.17950)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/63a369d98c0c89dcae3b8329/AiH2zjy1cnt9OADAAZMLD.jpeg) AdinaY
[ 4 ](https://huggingface.co/login?next=%2Fpapers%2F2510.17950)
### [RoboChallenge: Large-scale Real-robot Evaluation of Embodied Policies](https://huggingface.co/papers/2510.17950)
[![RoboChallenge](https://cdn-uploads.huggingface.co/production/uploads/68d9ff7b646abb43021b3e7d/ueC9pjiYd8lrzptIbUVFs.jpeg) RoboChallenge.ai](https://huggingface.co/RoboChallenge)
[](https://huggingface.co/papers/2510.17950#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.04668.png)](https://huggingface.co/papers/2511.04668)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/626dc5105f7327906f0b2a4e/QCSzuwYqsv8ozRnusVb-F.jpeg) ellisbrown
[ 3 ](https://huggingface.co/login?next=%2Fpapers%2F2511.04668)
### [SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding](https://huggingface.co/papers/2511.04668)
[![nyu-visionx](https://cdn-uploads.huggingface.co/production/uploads/626dc5105f7327906f0b2a4e/Kn-QtZjE6TJE-syTndXIW.jpeg) NYU VisionX](https://huggingface.co/nyu-visionx)
[](https://huggingface.co/papers/2511.04668#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.03996.png)](https://huggingface.co/papers/2511.03996)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 3 ](https://huggingface.co/login?next=%2Fpapers%2F2511.03996)
### [Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots](https://huggingface.co/papers/2511.03996)
[![ByteDance-Seed](https://cdn-uploads.huggingface.co/production/uploads/6535c9e88bde2fae19b6fb25/flkDUqd_YEuFsjeNET3r-.png) ByteDance Seed](https://huggingface.co/ByteDance-Seed)
[](https://huggingface.co/papers/2511.03996#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02309.png)](https://huggingface.co/papers/2511.02309)
Submitted by ![](https://huggingface.co/avatars/44d59b5d951a4303def15ea1c6e3387e.svg) paraslossfunk
[ 3 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02309)
### [The Sequential Edge: Inverse-Entropy Voting Beats Parallel Self-Consistency at Matched Compute](https://huggingface.co/papers/2511.02309)
[![Lossfunk](https://cdn-uploads.huggingface.co/production/uploads/67a128ecc9bce54bbf006876/1lIRZ5gmsWovgosI_HIXy.jpeg) Lossfunk](https://huggingface.co/Lossfunk)
[](https://huggingface.co/papers/2511.02309#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01202.png)](https://huggingface.co/papers/2511.01202)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/68b65343dd7f21b75891e446/g4dtudmiuSBZY63eLFxJ8.jpeg) niuxueyan
[ 3 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01202)
### [Forget BIT, It is All about TOKEN: Towards Semantic Information Theory for LLMs](https://huggingface.co/papers/2511.01202)
[
  * · 1 authors 

](https://huggingface.co/papers/2511.01202)
[](https://huggingface.co/papers/2511.01202#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01144.png)](https://huggingface.co/papers/2511.01144)
Submitted by ![](https://huggingface.co/avatars/4d2fb7c1a5ad5dabdb8888fa2fe72e65.svg) Tanvirul
[ 3 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01144)
### [AthenaBench: A Dynamic Benchmark for Evaluating LLMs in Cyber Threat Intelligence](https://huggingface.co/papers/2511.01144)
[
  * · 5 authors 

](https://huggingface.co/papers/2511.01144)
[1](https://huggingface.co/papers/2511.01144) [](https://huggingface.co/papers/2511.01144#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.00810.png)](https://huggingface.co/papers/2511.00810)
Submitted by ![](https://huggingface.co/avatars/c9a248b8d70b1a8f7b78265c98690570.svg) zhangry868
[ 3 ](https://huggingface.co/login?next=%2Fpapers%2F2511.00810)
### [GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding](https://huggingface.co/papers/2511.00810)
[
  * · 7 authors 

](https://huggingface.co/papers/2511.00810)
[2](https://huggingface.co/papers/2511.00810) [](https://huggingface.co/papers/2511.00810#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.27656.png)](https://huggingface.co/papers/2510.27656)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg) nielsr
[ 3 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27656)
### [RDMA Point-to-Point Communication for LLM Systems](https://huggingface.co/papers/2510.27656)
[![perplexity-ai](https://cdn-uploads.huggingface.co/production/uploads/64b89bf66b5ee8c38859cbd6/l_27fD52uFMZUXdFdY9fR.png) Perplexity](https://huggingface.co/perplexity-ai)
[](https://huggingface.co/papers/2510.27656#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.20150.png)](https://huggingface.co/papers/2510.20150)
Submitted by ![](https://huggingface.co/avatars/e10e2f8516d1451fd85e17b5a0ba978d.svg) yaochenzhu
[ 3 ](https://huggingface.co/login?next=%2Fpapers%2F2510.20150)
### [Rank-GRPO: Training LLM-based Conversational Recommender Systems with Reinforcement Learning](https://huggingface.co/papers/2510.20150)
[![netflix](https://cdn-uploads.huggingface.co/production/uploads/68d2e3609537cbef66612ae8/MJuH26GOdHAZYObE9QOYA.png) Netflix](https://huggingface.co/netflix)
[](https://huggingface.co/papers/2510.20150#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.03718.png)](https://huggingface.co/papers/2511.03718)
Submitted by ![](https://huggingface.co/avatars/ea9e762b3db755fe051751577353fbca.svg) chnln
[ 2 ](https://huggingface.co/login?next=%2Fpapers%2F2511.03718)
### [Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask](https://huggingface.co/papers/2511.03718)
[![cs-nlp-uu](https://cdn-uploads.huggingface.co/production/uploads/6305d542435ec751b72434b8/A9YelDlLilyEoGkqaksoL.png) NLP Group at Utrecht University](https://huggingface.co/cs-nlp-uu)
[](https://huggingface.co/papers/2511.03718#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02490.png)](https://huggingface.co/papers/2511.02490)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/67a3002c637d195f3c4bf371/-9G1DvjGpODiq5vwjLANF.png) rajandasgupta
[ 2 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02490)
### [BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and Monitoring](https://huggingface.co/papers/2511.02490)
[![eliteresearch](https://cdn-uploads.huggingface.co/production/uploads/68b97676948b70f005d923fe/2QCfcp6rhnh8GI6AVJ_yQ.png) ELITE Research Lab](https://huggingface.co/eliteresearch)
[](https://huggingface.co/papers/2511.02490#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02415.png)](https://huggingface.co/papers/2511.02415)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 2 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02415)
### [ChartM^3: A Multi-Stage Code-Driven Pipeline for Constructing Multi-Dimensional and Multi-Step Visual Reasoning Data in Chart Comprehension](https://huggingface.co/papers/2511.02415)
[
  * · 5 authors 

](https://huggingface.co/papers/2511.02415)
[](https://huggingface.co/papers/2511.02415#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02358.png)](https://huggingface.co/papers/2511.02358)
Submitted by ![](https://huggingface.co/avatars/8e1b59565ec5e4b31090cf1b911781b9.svg) wongyukim
[ 2 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02358)
### [Let Multimodal Embedders Learn When to Augment Query via Adaptive Query Augmentation](https://huggingface.co/papers/2511.02358)
[
  * ![](https://huggingface.co/avatars/8e1b59565ec5e4b31090cf1b911781b9.svg)
  * · 5 authors 

](https://huggingface.co/papers/2511.02358)
[](https://huggingface.co/papers/2511.02358#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01617.png)](https://huggingface.co/papers/2511.01617)
Submitted by ![](https://huggingface.co/avatars/8bcaf3cb3482a002ded96d3206b04947.svg) mohammad2012191
[ 2 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01617)
### [Vote-in-Context: Turning VLMs into Zero-Shot Rank Fusers](https://huggingface.co/papers/2511.01617)
[![KAUST](https://cdn-uploads.huggingface.co/production/uploads/6315fb0b29411a6864b05b35/6egitr9tcwgl5i6ikCbkY.jpeg) King Abdullah University of Science and Technology](https://huggingface.co/KAUST)
[1](https://huggingface.co/papers/2511.01617) [](https://huggingface.co/papers/2511.01617#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.26345.png)](https://huggingface.co/papers/2510.26345)
Submitted by ![](https://huggingface.co/avatars/d5bee04ac08fbfd0da70f84c535aba7d.svg) mxpoliakov
[ 2 ](https://huggingface.co/login?next=%2Fpapers%2F2510.26345)
### [MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data](https://huggingface.co/papers/2510.26345)
[
  * ![](https://huggingface.co/avatars/d5bee04ac08fbfd0da70f84c535aba7d.svg)
  * · 2 authors 

](https://huggingface.co/papers/2510.26345)
[2](https://huggingface.co/papers/2510.26345) [](https://huggingface.co/papers/2510.26345#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.24932.png)](https://huggingface.co/papers/2510.24932)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/66fc42b48bf64649c684b479/7ja7AWVPELZmHMUmIhaPP.jpeg) deeponh
[ 2 ](https://huggingface.co/login?next=%2Fpapers%2F2510.24932)
### [RiddleBench: A New Generative Reasoning Benchmark for LLMs](https://huggingface.co/papers/2510.24932)
[![ai4bharat](https://cdn-uploads.huggingface.co/production/uploads/1645373988267-5fbfc7a6e366524fe8e97ccf.png) AI4Bharat](https://huggingface.co/ai4bharat)
[](https://huggingface.co/papers/2510.24932#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.04583.png)](https://huggingface.co/papers/2511.04583)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6527b37c0ae663e384eb1b85/zKWa8h6YU4BWfcitpM5Pl.png) AtsuMiyai
[ 1 ](https://huggingface.co/login?next=%2Fpapers%2F2511.04583)
### [Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper](https://huggingface.co/papers/2511.04583)
[![hal-utokyo](https://cdn-uploads.huggingface.co/production/uploads/65d86a59bdb95b4bbc744e10/FOjSKBb6nGV-BBRp9fQU5.png) Hal Lab UTokyo](https://huggingface.co/hal-utokyo)
[](https://huggingface.co/papers/2511.04583#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02712.png)](https://huggingface.co/papers/2511.02712)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 1 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02712)
### [VidEmo: Affective-Tree Reasoning for Emotion-Centric Video Foundation Models](https://huggingface.co/papers/2511.02712)
[
  * · 7 authors 

](https://huggingface.co/papers/2511.02712)
[](https://huggingface.co/papers/2511.02712#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02374.png)](https://huggingface.co/papers/2511.02374)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/64d22cc68f912d78587f396f/g50XH8IbGu5uG3X02CDrM.jpeg) vjdevane
[ 1 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02374)
### [AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda](https://huggingface.co/papers/2511.02374)
[![bharatgenai](https://cdn-uploads.huggingface.co/production/uploads/67b462a1f4f414c2b3e2bc2f/EnVeNWEIeZ6yF6ueZ7E3Y.jpeg) BharatGen AI](https://huggingface.co/bharatgenai)
[](https://huggingface.co/papers/2511.02374#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02366.png)](https://huggingface.co/papers/2511.02366)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg) taesiri
[ 1 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02366)
### [LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context](https://huggingface.co/papers/2511.02366)
[
  * · 18 authors 

](https://huggingface.co/papers/2511.02366)
[](https://huggingface.co/papers/2511.02366#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02280.png)](https://huggingface.co/papers/2511.02280)
Submitted by ![](https://huggingface.co/avatars/9246c9ef06d80bd8628426375c95d4be.svg) Shuhuhuhu
[ 1 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02280)
### [SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL Tuning](https://huggingface.co/papers/2511.02280)
[![BytedanceDouyinContent](https://cdn-uploads.huggingface.co/production/uploads/675a9a9972aadf30cae14112/FRutS5CvFUHGdun8uybJ5.jpeg) BytedanceDouyinContent](https://huggingface.co/BytedanceDouyinContent)
[](https://huggingface.co/papers/2511.02280#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.02219.png)](https://huggingface.co/papers/2511.02219)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/652fc2605615e57807e3db19/kbRcpR0YFQnU3IlziqCHf.png) arnodjiang
[ 1 ](https://huggingface.co/login?next=%2Fpapers%2F2511.02219)
### [TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning in Tabular Data](https://huggingface.co/papers/2511.02219)
[
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/652fc2605615e57807e3db19/kbRcpR0YFQnU3IlziqCHf.png)
  * · 5 authors 

](https://huggingface.co/papers/2511.02219)
[](https://huggingface.co/papers/2511.02219#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01706.png)](https://huggingface.co/papers/2511.01706)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/637390430938c0754238276c/O7IIJdZsS9yjznh780XwA.jpeg) sekhcopenlu
[ 1 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01706)
### [Multi-Step Knowledge Interaction Analysis via Rank-2 Subspace Disentanglement](https://huggingface.co/papers/2511.01706)
[
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/637390430938c0754238276c/O7IIJdZsS9yjznh780XwA.jpeg)
  * · 3 authors 

](https://huggingface.co/papers/2511.01706)
[0](https://huggingface.co/papers/2511.01706) [](https://huggingface.co/papers/2511.01706#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01502.png)](https://huggingface.co/papers/2511.01502)
Submitted by ![](https://huggingface.co/avatars/103c790078d5e8c6f7e141de42c8e261.svg) mengtanZ
[ 1 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01502)
### [Discriminately Treating Motion Components Evolves Joint Depth and Ego-Motion Learning](https://huggingface.co/papers/2511.01502)
[
  * · 9 authors 

](https://huggingface.co/papers/2511.01502)
[](https://huggingface.co/papers/2511.01502#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.01450.png)](https://huggingface.co/papers/2511.01450)
Submitted by ![](https://huggingface.co/avatars/564338e32bd475dd0265f417fd5c7632.svg) dujielvtqs
[ 1 ](https://huggingface.co/login?next=%2Fpapers%2F2511.01450)
### [Reg-DPO: SFT-Regularized Direct Preference Optimization with GT-Pair for Improving Video Generation](https://huggingface.co/papers/2511.01450)
[![ByteDance](https://cdn-uploads.huggingface.co/production/uploads/6535c9e88bde2fae19b6fb25/0clr54wj5Ly-RkYU9OXPp.png) ByteDance](https://huggingface.co/ByteDance)
[0](https://huggingface.co/papers/2511.01450) [](https://huggingface.co/papers/2511.01450#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.27224.png)](https://huggingface.co/papers/2510.27224)
Submitted by ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6422eab8e2029ade06eeee2c/Gai3BHr2WJ0YuhdumqQ_z.png) MElHuseyni
[ 1 ](https://huggingface.co/login?next=%2Fpapers%2F2510.27224)
### [Mask-to-Height: A YOLOv11-Based Architecture for Joint Building Instance Segmentation and Height Classification from Satellite Imagery](https://huggingface.co/papers/2510.27224)
[
  * ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6422eab8e2029ade06eeee2c/Gai3BHr2WJ0YuhdumqQ_z.png)
  * · 4 authors 

](https://huggingface.co/papers/2510.27224)
[](https://huggingface.co/papers/2510.27224#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.25080.png)](https://huggingface.co/papers/2510.25080)
Submitted by ![](https://huggingface.co/avatars/cd2a2b049bc7e4b0f79965e1f54ba25c.svg) cavaunpeu
[ 1 ](https://huggingface.co/login?next=%2Fpapers%2F2510.25080)
### [Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response Games](https://huggingface.co/papers/2510.25080)
[
  * ![](https://huggingface.co/avatars/cd2a2b049bc7e4b0f79965e1f54ba25c.svg)
  * · 1 authors 

](https://huggingface.co/papers/2510.25080)
[](https://huggingface.co/papers/2510.25080#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.24078.png)](https://huggingface.co/papers/2510.24078)
Submitted by ![](https://huggingface.co/avatars/ffa5dcab545715c037f4a2fa7c5ffbab.svg) yang-william
[ 1 ](https://huggingface.co/login?next=%2Fpapers%2F2510.24078)
### [Beyond Objects: Contextual Synthetic Data Generation for Fine-Grained Classification](https://huggingface.co/papers/2510.24078)
[
  * ![](https://huggingface.co/avatars/ffa5dcab545715c037f4a2fa7c5ffbab.svg)
  * · 5 authors 

](https://huggingface.co/papers/2510.24078)
[](https://huggingface.co/papers/2510.24078#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.19278.png)](https://huggingface.co/papers/2510.19278)
Submitted by ![](https://huggingface.co/avatars/3c5f5c1140024c084bf8c8d935dd3d90.svg) n-yoo
[ 1 ](https://huggingface.co/login?next=%2Fpapers%2F2510.19278)
### [D2D: Detector-to-Differentiable Critic for Improved Numeracy in Text-to-Image Generation](https://huggingface.co/papers/2510.19278)
[
  * ![](https://huggingface.co/avatars/3c5f5c1140024c084bf8c8d935dd3d90.svg)
  * · 3 authors 

](https://huggingface.co/papers/2510.19278)
[](https://huggingface.co/papers/2510.19278#community)
[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.00956.png)](https://huggingface.co/papers/2511.00956)
Submitted by ![](https://huggingface.co/avatars/5795283123829a42e0687df3b4f5689c.svg) liushanyuan18
[ - ](https://huggingface.co/login?next=%2Fpapers%2F2511.00956)
### [EVTAR: End-to-End Try on with Additional Unpaired Visual Reference](https://huggingface.co/papers/2511.00956)
[![qihoo360](https://cdn-uploads.huggingface.co/production/uploads/660697054c0882ce77fe3160/fVsqY-Q0DDrme0zyN_zLa.png) 北京奇虎科技有限公司](https://huggingface.co/qihoo360)
[](https://huggingface.co/papers/2511.00956#community)
[](https://huggingface.co/papers/month/2025-10)
Company
[TOS](https://huggingface.co/terms-of-service) [Privacy](https://huggingface.co/privacy) [About](https://huggingface.co/huggingface) [Jobs](https://apply.workable.com/huggingface/) [](https://huggingface.co/)
Website
[Models](https://huggingface.co/models) [Datasets](https://huggingface.co/datasets) [Spaces](https://huggingface.co/spaces) [Pricing](https://huggingface.co/pricing) [Docs](https://huggingface.co/docs)
